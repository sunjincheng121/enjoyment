---
title: Apache Flink 说道系列- Python API 时代的产物
date: 2019-07-21 23:05:15
categories: Apache Flink 说道
tags: [Flink, 道德经,上善若水]
---

# 开篇说道-上善若水

我们常说"知识就是力量", "力量"也意味着"能力"，"能力"在没有增加任何限定词语的时候往往是指一个人的综合素质。比如，当阅读本文时候你是想学习Flink Python API如果你很快就能普获道重点，这是学习能力！再如，在我写这篇博文的角度说，如果我写的内容晦涩难懂，那就体现了文字表达能力问题。所以"能力"是包含方方面面的综合素质的体现！那么本篇我们说道的内容就是当你具备了很高的"能力"之后，具体一点就是如果由于你的能力突出做了领导，你将如何处理和你能力相当或者能力不如你的人的关系呢？就此你思考10秒看看你脑子里的答案是什么？

我想能阅读本篇文章的人都是一心向善，与人友善的好同学，但是在内心很清楚"友善"的原则并且在与人发生矛盾时候妥善解决(大多数谦让他人)的同时自己的内心也能做到愉悦和平静的同学请在本篇评论区留言:) 

回答刚才的问题: "如何处理和你能力相当或者能力不如你的人的关系呢？" 我的建议是："上善若水"，出自老子的《道德经第八章》。老子用水来表达与人为事的自然之道。水至柔，她可以根据与之接触的各种物体的形状改变自己，她以各种形态存在，可以化作甘露滋润万物，可以凝聚江河载船运物！水至刚，她可以滴水穿石、无坚不摧！"刚"是一种能力，"柔"是一种态度，水有能力，但却始终 以一种谦和的低姿态，从高处流往低处！在《道德经》中老子更强调的是自然，任何事情符合自然规律！所谓"无为"并不是"无作为"而是"不违背自然规律"。所以遇到与人发生矛盾的时候，要心怀包容之心，水至柔可以容纳万物之形，人在有能力的时候也要容纳各色之人，容纳"蛮不讲理"之人，因为我们不能"以蛮治蛮",容纳"污言秽语"之人，因为"身正影自直"，容纳"处处与你为敌"之人，因为"孤掌难鸣"，你不理它，它自消去。容纳"能弱气盛"之人，因为他因"能力不足而容易暴躁"，只要你诚心助之，让他靠自己能力而得到认可，气自然消失，最终也会变得言和语悦！所以任何事情的发生都有气必然的道理，尊重事实，顺其自然，永远修行自身，位高而卑谦，**上善若水**，与世无争, 无争于世！

![](B83130D4-9E1F-4BBC-88FA-2286951D18E5.png)

# 为啥需要 Python API
开篇"上善若水"的与人之道是我们正式介绍Python API之前的开胃菜。希望是真的开胃，你还有胃口继续读完全篇。那么Apache Flink 的runtime是用Java编写的，为啥还需要增加对Python的支持呢？也许大家都很清楚，目前很多著名的开源项目都支持Python，比如Beam，spark，kafka等，Flink自然也需要增加对Python的支持，这个角度分析也许很好，但我们想想为啥这些非常火热的项目都纷纷支持Python呢？Python语言有怎样的"魔力"让这些著名的项目都青睐于他？我们看一统计数据：

## 最流行的编程语言
我们看看行业分析公司[RedMonk](https://redmonk.com/sogrady/2019/07/18/language-rankings-6-19/)最新的最受欢迎的语言排名数据如下：
![](DF105B35-22A0-4981-AABB-3C03EDF4AFCA.png)
上图从github和Stack Overflow两个维度进行分析的前十名如下：
* JavaScript
* Java
* Python
* PHP
* C++
* C#
* CSS
* Ruby
* C
* TypeScript

我们发现Pytnon排在了第3名，目前也非常流行的R和Go语言排在了15和16名。这个很客观的分享足以证明Python的受众是多么的庞大，任何项目对Python的支持就是在无形的扩大项目的受众用户！

## 互联网最火热的领域
就目前而言互联网最热的领域应该是大数据计算，以前单机的计算时代已经过去了，为啥单机时代过去了？因为单机处理能力的提高速度远远落后于数据的与日俱增的速度，以几个方面看看为啥目前处于大数据时代，而最炽热的互联网领域是大数据计算？

### 为啥是大数据时代 - 数据量与日俱增

随着云计算、物联网、人工智能等信息技术的快速发展，数据量呈现几何级增长，我们先看一份预测数据，全球数据总量在短暂的10年时间会由16.1ZB增长到163ZB，数据量的快速增长已经远远超越单个计算机存储和处理能力，如下：

![](9B952F03-53BF-43DF-8051-A2FAC84A600C.png)


上图我们数据量的单位是ZB，我们简单介绍一下数据量的统计单位，基本单位是bit，按顺序给出所有单位：bit、Byte、KB、MB、GB、TB、PB、EB、ZB、YB、BB、NB、DB。他们之间的转换关系是：

* 1 Byte =8 bit
* 1 KB = 1,024 Bytes 
* 1 MB = 1,024 KB 
* 1 GB = 1,024 MB 
* 1 TB = 1,024 GB 
* 1 PB = 1,024 TB 
* 1 EB = 1,024 PB 
* 1 ZB = 1,024 EB 
* 1 YB = 1,024 ZB 
* 1 BB = 1,024 YB 
* 1 NB = 1,024 BB 
* 1 DB = 1,024 NB 

看到上面的数据量也许我们会质疑全球数据真的有这么恐怖吗？数据都从哪里来的呢? 其实我看到这个数据也深表质疑，但是仔细查阅了一下资料，发现全球数据的确在快速的增长着，比如 Fecebook社交平台每天有几百亿，上千亿的照片数据，纽约证券交易每天有几TB的交易数据，再说说刚刚发生的阿里巴巴2018年双11数据，从交易额上创造了2135亿的奇迹，从数据量上看仅仅是Alibaba内部的监控日志处理看就达到了162GB/秒。所以Alibaba为代表的互联网行业，也促使了数据量的急速增长，同样以Alibaba双11近10年来的成交额来用数字证明数据的增长，如下：

![](1AF4C656-6ABA-4F69-A771-E6EC623B382D.png)

### 数据价值的产生 - 数据分析

我们如何让大数据产生价值呢？毋庸置疑，对大数据进行统计分析，让那个统计分析的结果帮助我们进行决策。比如 推荐系统，我们可以根据一个用户长期的购买习惯，购买记录来分析其兴趣爱好，进而可以准确的进行有效推荐。那么面对上面的海量数据，在一台计算机上无法处理，那么我们如何在有限的时间内对全部数据进行统计分析呢？提及这个问题，我们不得不感谢Google发布的三大论文：

* GFS - 2003年，Google发布Google File System论文，这是一个可扩展的分布式文件系统，用于大型的、分布式的、对大量数据进行访问的应用。
* MapReduce - 2004年， Google发布了MapReduce论文，论文描述了大数据的分布式计算方式，主要思想是将任务分解然后在多台处理能力较弱的计算节点中同时处理，然后将结果合并从而完成大数据处理。Mapreduce是针对分布式并行计算的一套编程模型，如下图所示：

![](B31690BA-A8E2-4C22-A948-8735728542B0.png)

* BigTable - 2006年, Google由发布了BigTable论文，是一款典型是NoSQL分布式数据库。

受益于Google的三大论文，Apache开源社区迅速开发了Hadoop生态系统，HDFS，MapReduce编程模型，NoSQL数据库HBase。并很快得到了全球学术界和工业界的普遍关注，并得到推广和普及应用。其中Alibaba在2008年就启动了基于hadoop的云梯项目，hadoop就成为了Alibaba分布式计算的核心技术体系，并在2010年就达到了千台机器的集群，hadoop在Alibaba的集群发展如下：

![](1DB881D1-4605-4AA3-ABCB-34BC8E765D79.png)

但利用Hadoop进行MapReduce的开发，需要开发人员精通Java语言，并要对apReduce的运行原理有一定的了解，这样在一定程度上提高了MapReduce的开发门槛，所以在开源社区又不断涌现了一些为了简化MapReduce开发的开源框架，其中Hive就是典型的代表。HSQL可以让用户以类SQL的方式描述MapReduce计算，比如原本需要几十行，甚至上百行才能完成的wordCount，用户一条SQL语句就能完成了，这样极大的降低了MapReduce的开发门槛。这样Hadoop技术生态不断发展，基于Hadoop的分布式的大数据计算逐渐普及在业界家喻户晓！

### 数据价值最大化 - 时效性
每一条数据都是一条信息，信息的时效性是指从信息源发送信息后经过接收、加工、传递、利用的时间间隔及其效率。时间间隔越短，时效性越强。一般时效性越强，信息所带来的价值越大，比如一个偏好推荐场景，用户在购买了一个“蒸箱”，如果能在秒级时间间隔给用户推荐一个“烤箱”的优惠产品，那么用户购买“烤箱”的概率会很高，那么在1天之后根据用户购买“蒸箱”的数据，分析出用户可能需要购买“烤箱”，那么我想这条推荐信息被用户采纳的可能性将大大降低。基于这样数据时效性问题，也暴露了Hadoop批量计算的弊端，就是实时性不高。基于这样的时代需求，典型的实时计算平台也应时而生，2009年Spark诞生于UCBerkeley的AMP实验室， 2010年Storm的核心概念于BackType被Nathan提出。Flink也以一个研究性的项目于2010年开始于德国柏林。

## 阿尔法 - 人工智能
在2016谷歌阿尔法围棋以4:1战胜围棋世界冠军、职业九段棋手李世石之后，人们逐渐用新的眼光审视让深度学习，而且掀起了人工智能的“狂热”。百度百科对人工智能(Artificial Intelligence)，英文缩写为AI的定义是: 人工智能是研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门新技术科学。

![](6669AE2D-CBB7-49AB-A339-4E5ACCA99813.png)

而机器学习是进行人工智能的一种方法或者工具。机器学习在以Spark，Flink为首的大数据技术平台中具有较高的地位，尤其Spark近些年在ML方面做了巨大的努力，同时PySpark集成了很多优秀的机器学习类库，如典型的Pandas，在这方面远远超过了Flink，所以Flink正面面对自己的不足，在Flink1.9中开启了新的ML接口和新的flink-python模块！

那么机器学习的重要和Python又有什么关系呢？我们一下统计数据，看什么语言是最流行的机器学习语言？
IBM 的数据科学家 Jean-Francois Puget 曾经做过一个有趣的分析。他爬取了著名的求职网站 indeed 上雇主的岗位要求变动趋势，来评估当下市场上最受欢迎的岗位语言。其中当他单独搜索"machine learning"时候，也可以得到一个近似的结果:
![](070B3285-C790-4D6F-BB9B-6981756255CA.jpg)
其结构发现Python是与热的"machine learning"，虽然这是2016年的调查，但是也足以证明Python在"machine learning"方面的地位，同时上面我们提到的redmonk的统计数据也足以证明这一点！

不仅仅是各种调查，我们也可以从Python的特点和现有的Python生态来说说为什么Python是机器学习的最好语言。

Python 是一种面向对象的解释型程序语言，由荷兰人(Guido van Rossum)于1989年发明，并于1991年发布了第一个版。Python 作为解释型语言，虽然跑得比谁都慢，但Python设计者的哲学是"用一种方法并且只有一种方法来做一件事"。在开发新的Python语法时，如果面临多种选择，Python开发者一般会选择明确的没有或者很少有歧义的语法。简单易学的特点促使了Python有庞大的用户群体，进而很多机器学习的类库也是由Python开发的，比如：NumPy、SciPy和结构化数据操作可以通过Pandas等等。所以Python这种丰富的生态系统为机器学习提供了一定程度的便利性，也必然成为了最受欢迎的机器学习语言！

# 小结
本篇重点描述了Apache Flink 为啥需要支持Python API。以实际数字说明目前我们处于一个大数据时代，数据的价值要依靠大数据分析，而由于数据的时效性的重要性而催生了著名的Apache Flink流式计算平台。目前在大数据计算时代，AI是赤手可热的发展方向，机器学习是AI的重要手段之一，而恰恰由于语言的特点和生态的优势，Python成为了机器学习最重要的语言，进而推出Apache Flink 着手发力 Flink API的动机！所谓时势造英雄，Apache Flink Python API是时代的产物，水其自然而得之的必然！最后再次强调本篇所提的 "上善如水"的为人之道值得我们以实际生活来慢慢体会！

# 鼓励是动力&建议是马力
本系列文章难免有很多缺陷和不足，真诚希望读者对有收获的篇章给予点赞鼓励，因为那是我持续更新的动力！对有不足的篇章给予反馈和建议，因为那是不断提高文章质量的马力！再次感谢大家对本篇文章的查阅！下篇见...

