---
title: Apache Flink è¯´é“ç³»åˆ— - PyFlink ä½œä¸šçš„å¤šç§éƒ¨ç½²æ¨¡å¼
date: 2020-01-02 17:15:18
categories: Apache Flink è¯´é“
tags: [Flink, é“å¾·ç», è‡´è™šæå®ˆé™ç¬ƒ]
---

# å¼€ç¯‡è¯´é“
è€å­è¯´ï¼šâ€œè‡´è™šæï¼Œå®ˆé™ç¬ƒã€‚ä¸‡ç‰©å¹¶ä½œï¼Œå¾ä»¥è§‚å…¶å¤"ã€‚ å­—é‡Œè¡Œé—´æ˜¯å‘Šè¯‰äººä»¬è¦å°½é‡ä½¿å¿ƒçµè¾¾åˆ°è™šå¯‚çš„æè‡´ï¼ŒæŒä¹‹ä»¥æ’çš„åšå®ˆå®é™ã€‚è€å­è®¤ä¸ºâ€œè™šâ€å’Œâ€œé™â€æ˜¯å¿ƒçµçš„æœ¬åˆçš„çŠ¶æ€ï¼Œä¹Ÿåº”è¯¥æ˜¯ä¸€ç§å¸¸æ€ï¼Œå³ï¼Œæ˜¯ä¸€ç§æ²¡æœ‰å¿ƒæœºï¼Œæ²¡æœ‰æˆè§ï¼Œæ²¡æœ‰å¤–ç•Œååˆ©ï¼Œç‰©è´¨è¯±æƒ‘ï¼Œè€Œä¿æŒçš„çŠ¶æ€ã€‚å½“è¾¾åˆ°è¿™ä¸ªçŠ¶æ€ä¹‹åï¼Œå°±å¯ä»¥é™è§‚ä¸‡ç‰©çš„è“¬å‹ƒå‘å±•ï¼Œäº†è§£ä¸‡ç‰©çš„å¾ªç¯å¾€å¤çš„å˜åŒ–ï¼Œé€šæ™“è‡ªç„¶ä¹‹ç†ï¼Œä½“æ‚Ÿè‡ªç„¶ä¹‹é“ã€‚

"è‡´è™šæï¼Œå®ˆé™ç¬ƒ" å¹¶ä¸ä»£è¡¨å¯¹ä»»ä½•äº‹æƒ…æ— åŠ¨äºè¡·ï¼Œè€Œæ˜¯é€šè¿‡ "è‡´è™šæï¼Œå®ˆé™ç¬ƒ" çš„æ–¹å¼äº†è§£ä¸‡ç‰©å˜åŒ–çš„æ ¹æºï¼Œå°±å¥½æ¯”ï¼Œçœ‹åˆ°æ–°èŠ½ä¸æƒŠï¼Œçœ‹åˆ°è½å¶ä¸å“€ï¼Œå› ä¸ºæˆ‘ä»¬çŸ¥é“ï¼Œè½å¶å½’æ ¹ï¼Œé‡å½’æ³¥åœŸä¹‹åï¼Œè¿˜ä¼šå†ç ´åœŸè€Œå‡ºï¼Œå¼€å§‹æ–°çš„è½®å›ã€‚

åœ¨2020å¹´1æœˆ1æ—¥é›¶ç‚¹æˆ‘å‘äº†ä¸€æ¡æœ‹å‹åœˆï¼Œå¯¹è‡ªå·±çš„ç¥ç¦æ˜¯ï¼š"ãŠ—ï¸ 2020 å®‰"ã€‚
![](15776987959455/15779569378844.jpg)
å½“ç„¶è¿™é‡Œæˆ‘ä¹Ÿç¥ç¦æ‰€æœ‰çœ‹åˆ°è¿™ç¯‡åšå®¢çš„ä½ : "ãŠ—ï¸ 2020 å®‰"ã€‚ ç¥ç¦å¤§å®¶ "å®‰"ï¼Œä¹Ÿå³ç¥ç¦å¤§å®¶ èƒ½å¤Ÿåœ¨æ–°çš„ä¸€å¹´ï¼Œè¿½æ±‚å†…å¿ƒçš„ä¿®ç‚¼ï¼Œæ‘’å»çº·çº·å¤æ‚çš„ç‰©æ¬²å¹²æ‰°ï¼Œæ‹‚å»å¿ƒçµçš„ç°å°˜ï¼Œä¿æŒè‡ªå·±çš„èµ¤å­ä¹‹å¿ƒï¼ 

# é“ç ´ "å¤©æœº"
å‰é¢ä¸€äº›åšå®¢å¤§å¤šä»‹ç»PyFlinkçš„åŠŸèƒ½å¼€å‘ï¼Œæ¯”å¦‚ï¼Œå¦‚ä½•ä½¿ç”¨å„ç§ç®—å­(Join/Window/AGG etc.)ï¼Œå¦‚ä½•ä½¿ç”¨å„ç§Connector(Kafka, CSV, Socket etc.)ï¼Œè¿˜æœ‰ä¸€äº›å®é™…çš„æ¡ˆä¾‹ã€‚è¿™äº›éƒ½åœç•™åœ¨å¼€å‘é˜¶æ®µï¼Œä¸€æ—¦å¼€å‘å®Œæˆï¼Œæˆ‘ä»¬å°±é¢ä¸´æ¿€åŠ¨äººå¿ƒçš„æ—¶åˆ»ï¼Œé‚£å°±æ˜¯ å°†æˆ‘ä»¬ç²¾å¿ƒè®¾è®¡å¼€å‘çš„ä½œä¸šè¿›è¡Œéƒ¨ç½²ï¼Œé‚£ä¹ˆé—®é¢˜æ¥äº†ï¼Œä½ çŸ¥é“æ€æ ·éƒ¨ç½²PyFlinkçš„ä½œä¸šå—ï¼Ÿè¿™ç¯‡å°†ä¸ºå¤§å®¶å…¨é¢ä»‹ç»éƒ¨ç½²PyFlinkä½œä¸šçš„å„ç§æ¨¡å¼ã€‚

# ç»„ä»¶æ ˆå›é¡¾
![](15776987959455/15777810183663.jpg)


ä¸Šé¢çš„ç»„ä»¶æ ˆé™¤äº†PyFlinkæ˜¯ç¬¬ä¸€æ¬¡æ·»åŠ ä¸Šå»ï¼Œå…¶ä»–éƒ¨åˆ†å¤§å®¶åº”è¯¥éå¸¸ç†Ÿæ‚‰äº†ã€‚ç›®å‰PyFlinkåŸºäºJavaçš„Table APIä¹‹ä¸Šï¼ŒåŒæ—¶åœ¨Runtimeå±‚é¢æœ‰Pythonçš„ç®—å­å’Œæ‰§è¡Œå®¹å™¨ã€‚é‚£ä¹ˆæˆ‘ä»¬èšç„¦é‡ç‚¹ï¼Œçœ‹æœ€åº•å±‚çš„ Deployéƒ¨åˆ†ï¼Œä¸Šå›¾æˆ‘ä»¬åˆ†æˆäº†ä¸‰ç§éƒ¨ç½²æ¨¡å¼ï¼ŒLocal/Cluster/Cloudï¼Œå…¶ä¸­Localæ¨¡å¼è¿˜æœ‰2ç§ä¸åŒæ–¹å¼ï¼Œä¸€æ˜¯SingleJVMï¼Œä¹Ÿå³æ˜¯MiniCluster, å‰é¢åšå®¢é‡Œé¢è¿è¡Œç¤ºä¾‹æ‰€ä½¿ç”¨çš„å°±æ˜¯MiniClusterã€‚äºŒæ˜¯SingleNodeï¼Œä¹Ÿå°±æ˜¯è™½ç„¶æ˜¯é›†ç¾¤æ¨¡å¼ï¼Œä½†æ˜¯æ‰€æœ‰è§’è‰²éƒ½åœ¨ä¸€å°æœºå™¨ä¸Šã€‚ä¸‹é¢æˆ‘ä»¬ç®€å•ä»‹ç»ä¸€ä¸‹ä¸Šé¢è¿™å‡ ç§éƒ¨ç½²æ¨¡å¼çš„åŒºåˆ«ï¼š
- Local-SingleJVM æ¨¡å¼- è¯¥æ¨¡å¼å¤§å¤šæ˜¯å¼€å‘æµ‹è¯•é˜¶æ®µä½¿ç”¨çš„æ–¹å¼ï¼Œæ‰€æœ‰è§’è‰²TMï¼ŒJMç­‰éƒ½åœ¨åŒä¸€ä¸ªJVMé‡Œé¢ã€‚
- Local-SingleNode æ¨¡å¼ - æ„åœ¨æ‰€æœ‰è§’è‰²éƒ½è¿è¡Œåœ¨åŒä¸€å°æœºå™¨ï¼Œç›´ç™½ä¸€ç‚¹å°±æ˜¯ä»è¿è¡Œçš„æ¶æ„ä¸Šçœ‹ï¼Œè¿™ç§æ¨¡å¼è™½ç„¶æ˜¯åˆ†å¸ƒå¼çš„ï¼Œä½†é›†ç¾¤èŠ‚ç‚¹åªæœ‰1ä¸ªï¼Œè¯¥æ¨¡å¼å¤§å¤šæ˜¯æµ‹è¯•å’ŒIoTè®¾å¤‡ä¸Šè¿›è¡Œéƒ¨ç½²ä½¿ç”¨ã€‚
- Cluster æ¨¡å¼ - ä¹Ÿå°±æ˜¯æˆ‘ä»¬ç»å¸¸ç”¨äºæŠ•äº§çš„åˆ†å¸ƒå¼éƒ¨ç½²æ–¹å¼ï¼Œä¸Šå›¾æ ¹æ®å¯¹èµ„æºç®¡ç†çš„æ–¹å¼ä¸åŒåˆåˆ†ä¸ºäº†å¤šç§ï¼Œå¦‚ï¼šStandalone æ˜¯Flinkè‡ªèº«è¿›è¡Œèµ„æºç®¡ç†ï¼ŒYARNï¼Œé¡¾åæ€ä¹‰å°±æ˜¯åˆ©ç”¨èµ„æºç®¡ç†æ¡†æ¶Yarnæ¥è´Ÿè´£Flinkè¿è¡Œèµ„æºçš„åˆ†é…ï¼Œè¿˜æœ‰ç»“åˆKubernetesç­‰ç­‰ã€‚
- Cloud æ¨¡å¼- è¯¥éƒ¨ç½²æ¨¡å¼æ˜¯ç»“åˆå…¶ä»–äº‘å¹³å°è¿›è¡Œéƒ¨ç½²ã€‚

æ¥ä¸‹æ¥æˆ‘ä»¬çœ‹çœ‹PyFlinkçš„ä½œä¸šå¯ä»¥è¿›è¡Œæ€æ ·çš„æ¨¡å¼éƒ¨ç½²ï¼Ÿ

# ç¯å¢ƒä¾èµ–
- JDK 1.8+ (1.8.0_211)
- Maven 3.x (3.2.5)
- Scala 2.11+ (2.12.0)
- Python 3.5+ (3.7.6)
- Git 2.20+ (2.20.1)

# æºç æ„å»ºåŠå®‰è£…
åœ¨Apache Flink 1.10 å‘å¸ƒä¹‹åï¼Œæˆ‘ä»¬é™¤äº†æºç æ„å»ºä¹‹å¤–ï¼Œè¿˜æ”¯æŒç›´æ¥åˆ©ç”¨pip install å®‰è£…PyFlinkã€‚é‚£ä¹ˆç°åœ¨æˆ‘ä»¬è¿˜æ˜¯ä»¥æºç æ„å»ºçš„æ–¹å¼è¿›è¡Œä»Šå¤©çš„ä»‹ç»ã€‚
- ä¸‹è½½æºç 

```
git clone https://github.com/apache/flink.git
```
- ç­¾å‡ºrelease-1.10åˆ†æ”¯(1.10ç‰ˆæœ¬æ˜¯PyFlinkçš„ç¬¬äºŒä¸ªç‰ˆæœ¬ï¼‰

```
git fetch origin release-1.10
git checkout -b release-1.10 origin/release-1.10
```
- æ„å»ºç¼–è¯‘

```
mvn clean package -DskipTests 
```
å¦‚æœä¸€èµ·é¡ºåˆ©ï¼Œä½ ä¼šæœ€ç»ˆçœ‹åˆ°å¦‚ä¸‹ä¿¡æ¯ï¼š

```
...
...
[INFO] flink-walkthrough-table-scala ...................... SUCCESS [  0.070 s]
[INFO] flink-walkthrough-datastream-java .................. SUCCESS [  0.081 s]
[INFO] flink-walkthrough-datastream-scala ................. SUCCESS [  0.067 s]
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  16:22 min
[INFO] Finished at: 2019-12-31T10:37:21+08:00
[INFO] ------------------------------------------------------------------------
```
- æ„å»ºPyFlinkå‘å¸ƒåŒ…

ä¸Šé¢æˆ‘ä»¬æ„å»ºäº†Javaçš„å‘å¸ƒåŒ…ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬æ„å»ºPyFlinkçš„å‘å¸ƒåŒ…,å¦‚ä¸‹ï¼š

```
cd flink-Python; Python setup.py sdist
```
æœ€ç»ˆè¾“å‡ºå¦‚ä¸‹ä¿¡æ¯ï¼Œè¯æ˜æ˜¯æˆåŠŸçš„ï¼š

```
copying pyflink/util/exceptions.py -> apache-flink-1.10.dev0/pyflink/util
copying pyflink/util/utils.py -> apache-flink-1.10.dev0/pyflink/util
Writing apache-flink-1.10.dev0/setup.cfg
creating dist
Creating tar archive
removing 'apache-flink-1.10.dev0' (and everything under it)
```
åœ¨distç›®å½•çš„apache-flink-1.10.dev0.tar.gzå°±æ˜¯æˆ‘ä»¬å¯ä»¥ç”¨äº`pip install`çš„PyFlinkåŒ….

- å®‰è£…PyFlink

ä¸Šé¢æˆ‘ä»¬æ„å»ºäº†PyFlinkçš„å‘å¸ƒåŒ…ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬åˆ©ç”¨pipè¿›è¡Œå®‰è£…ï¼Œæ£€æµ‹æ˜¯å¦ä¹‹å‰å·²ç»å®‰è£…è¿‡PyFlinkï¼Œå¦‚ä¸‹å‘½ä»¤ï¼š

```
pip3 list|grep flink
...
flink                         1.0      
pyflink-demo-connector        0.1 
```
ä¸Šé¢ä¿¡æ¯è¯´æ˜æˆ‘æœ¬æœºå·²ç»å®‰è£…è¿‡PyFlinkï¼Œæˆ‘ä»¬è¦å…ˆåˆ é™¤ï¼Œå¦‚ä¸‹ï¼š


```
pip3 uninstall flink
```
åˆ é™¤ä»¥å‰çš„å®‰è£…ä¹‹åï¼Œæˆ‘ä»¬å†å®‰è£…æ–°çš„å¦‚ä¸‹ï¼š
```
pip3 install dist/*.tar.gz

...
Successfully built apache-flink
Installing collected packages: apache-flink
Successfully installed apache-flink-1.10.dev0
```
æˆ‘ä»¬å†ç”¨listå‘½ä»¤æ£€æŸ¥ä¸€éï¼š


```
pip3 list|grep flink

...
apache-flink                  1.10.dev0
pyflink-demo-connector        0.1 
```
å…¶ä¸­`pyflink-demo-connector` æ˜¯æˆ‘ä»¥å‰åšå®éªŒæ—¶å€™çš„å®‰è£…ï¼Œå¯¹æœ¬ç¯‡æ²¡æœ‰å½±å“ã€‚

# å®‰è£…Apache Beam ä¾èµ–

æˆ‘ä»¬éœ€è¦ä½¿ç”¨Python3.5+ ç‰ˆæœ¬ï¼Œæ£€éªŒä¸€ä¸‹Pythonç‰ˆæœ¬ï¼Œå¦‚ä¸‹ï¼š
```
jincheng.sunjc$ Python --version
Python 3.7.6
```

æˆ‘æœ¬æœºæ˜¯Python3.7.6ï¼Œç°åœ¨æˆ‘ä»¬éœ€è¦å®‰è£…Apache Beamï¼Œå¦‚ä¸‹ï¼š

```
python -m pip install apache-beam==2.15.0

...
Installing collected packages: apache-beam
Successfully installed apache-beam-2.15.0
```
å¦‚æœé¡ºåˆ©çš„å‡ºç°ä¸Šé¢ä¿¡æ¯ï¼Œè¯´æ˜Apache-beamå·²ç»å®‰è£…æˆåŠŸã€‚

# PyFlinkç¤ºä¾‹ä½œä¸š

æ¥ä¸‹æ¥æˆ‘ä»¬å¼€å‘ä¸€ä¸ªç®€å•çš„PyFlinkä½œä¸šï¼Œæºç å¦‚ä¸‹ï¼š

```
import logging
import os
import shutil
import sys
import tempfile

from pyflink.table import BatchTableEnvironment, EnvironmentSettings
from pyflink.table.descriptors import FileSystem, OldCsv, Schema
from pyflink.table.types import DataTypes
from pyflink.table.udf import udf


def word_count():
   environment_settings = EnvironmentSettings.new_instance().in_batch_mode().use_blink_planner().build()
   t_env = BatchTableEnvironment.create(environment_settings=environment_settings)

   # register Results table in table environment
   tmp_dir = tempfile.gettempdir()
   result_path = tmp_dir + '/result'
   if os.path.exists(result_path):
       try:
           if os.path.isfile(result_path):
               os.remove(result_path)
           else:
               shutil.rmtree(result_path)
       except OSError as e:
           logging.error("Error removing directory: %s - %s.", e.filename, e.strerror)

   logging.info("Results directory: %s", result_path)

   # we should set the Python verison here if `Python` not point
   t_env.get_config().set_Python_executable("Python3")

   t_env.connect(FileSystem().path(result_path)) \
       .with_format(OldCsv()
                    .field_delimiter(',')
                    .field("city", DataTypes.STRING())
                    .field("sales_volume", DataTypes.BIGINT())
                    .field("sales", DataTypes.BIGINT())) \
       .with_schema(Schema()
                    .field("city", DataTypes.STRING())
                    .field("sales_volume", DataTypes.BIGINT())
                    .field("sales", DataTypes.BIGINT())) \
       .register_table_sink("Results")

   @udf(input_types=DataTypes.STRING(), result_type=DataTypes.ARRAY(DataTypes.STRING()))
   def split(input_str: str):
       return input_str.split(",")

   @udf(input_types=[DataTypes.ARRAY(DataTypes.STRING()), DataTypes.INT()], result_type=DataTypes.STRING())
   def get(arr, index):
       return arr[index]

   t_env.register_function("split", split)
   t_env.register_function("get", get)

   t_env.get_config().get_configuration().set_string("parallelism.default", "1")

   data = [("iPhone 11,30,5499,Beijing", ),
           ("iPhone 11 Pro,20,8699,Guangzhou", ),
           ("MacBook Pro,10,9999,Beijing", ),
           ("AirPods Pro,50,1999,Beijing", ),
           ("MacBook Pro,10,11499,Shanghai", ),
           ("iPhone 11,30,5999,Shanghai", ),
           ("iPhone 11 Pro,20,9999,Shenzhen", ),
           ("MacBook Pro,10,13899,Hangzhou", ),
           ("iPhone 11,10,6799,Beijing", ),
           ("MacBook Pro,10,18999,Beijing", ),
           ("iPhone 11 Pro,10,11799,Shenzhen", ),
           ("MacBook Pro,10,22199,Shanghai", ),
           ("AirPods Pro,40,1999,Shanghai", )]
   t_env.from_elements(data, ["line"]) \
       .select("split(line) as str_array") \
       .select("get(str_array, 3) as city, "
               "get(str_array, 1).cast(LONG) as count, "
               "get(str_array, 2).cast(LONG) as unit_price") \
       .select("city, count, count * unit_price as total_price") \
       .group_by("city") \
       .select("city, "
               "sum(count) as sales_volume, "
               "sum(total_price) as sales") \
       .insert_into("Results")

   t_env.execute("word_count")


if __name__ == '__main__':
   logging.basicConfig(stream=sys.stdout, level=logging.INFO, format="%(message)s")
   word_count()
```
æ¥ä¸‹æ¥æˆ‘ä»¬å°±ä»‹ç»å¦‚ä½•ç”¨ä¸åŒéƒ¨ç½²æ¨¡å¼è¿è¡ŒPyFlinkä½œä¸šï¼

# Local-SingleJVM æ¨¡å¼éƒ¨ç½²
è¯¥æ¨¡å¼å¤šç”¨äºå¼€å‘æµ‹è¯•é˜¶æ®µï¼Œç®€å•çš„åˆ©ç”¨`Python pyflink_job.py`å‘½ä»¤ï¼ŒPyFlinkå°±ä¼šé»˜è®¤å¯åŠ¨ä¸€ä¸ªLocal-SingleJVMçš„Flinkç¯å¢ƒæ¥æ‰§è¡Œä½œä¸šï¼Œå¦‚ä¸‹ï¼š

![](15776987959455/15777784863901.jpg)
é¦–å…ˆç¡®è®¤ä½ Pythonæ˜¯3.5+ï¼Œç„¶åæ‰§è¡Œä¸Šé¢çš„PyFlinkä½œä¸š`Python deploy_demo.py`,ç»“æœå†™å…¥åˆ°æœ¬åœ°æ–‡ä»¶ï¼Œç„¶å`cat`è®¡ç®—ç»“æœï¼Œå¦‚æœå‡ºç°å¦‚å›¾æ‰€ç¤ºçš„ç»“æœï¼Œåˆ™è¯´æ˜å‡†å¤‡å·¥ä½œå·²ç»å°±ç»ªã€‚:),å¦‚æœæœ‰é—®é¢˜ï¼Œæ¬¢è¿ç•™è¨€ï¼
è¿™é‡Œè¿è¡Œæ—¶SingleJVMï¼Œåœ¨è¿è¡Œè¿™ä¸ªjobæ—¶å€™å¤§å®¶å¯ä»¥æŸ¥çœ‹javaè¿›ç¨‹ï¼š

![](15776987959455/15777821361064.jpg)
æˆ‘ä»¬å‘ç°åªæœ‰ä¸€ä¸ªJVMè¿›ç¨‹ï¼Œé‡Œé¢åŒ…å«äº†æ‰€æœ‰Flinkæ‰€éœ€è§’è‰²ã€‚


# Local-SingleNode æ¨¡å¼éƒ¨ç½²
è¿™ç§æ¨¡å¼ä¸€èˆ¬ç”¨åœ¨å•æœºç¯å¢ƒä¸­è¿›è¡Œéƒ¨ç½²ï¼Œå¦‚IoTè®¾å¤‡ä¸­ï¼Œæˆ‘ä»¬ä»0å¼€å§‹è¿›è¡Œè¯¥æ¨¡å¼çš„éƒ¨ç½²æ“ä½œã€‚æˆ‘ä»¬è¿›å…¥åˆ°`flink/build-target`ç›®å½•ï¼Œæ‰§è¡Œå¦‚ä¸‹å‘½ä»¤(ä¸ªäººçˆ±å¥½ï¼Œæˆ‘æŠŠç«¯å£æ”¹æˆäº†8888)ï¼š

``` 
jincheng:build-target jincheng.sunjc$ bin/start-cluster.sh 
...
Starting cluster.
Starting standalonesession daemon on host jincheng.local.
```
æŸ¥çœ‹ä¸€ä¸‹Flinkçš„è¿›ç¨‹ï¼š

![](15776987959455/15777817105172.jpg)

æˆ‘ä»¬å‘ç°æœ‰TMå’ŒJMä¸¤ä¸ªè¿›ç¨‹ï¼Œè™½ç„¶åœ¨ä¸€å°æœºå™¨(Localï¼‰ä½†æ˜¯ä¹Ÿæ˜¯ä¸€ä¸ªé›†ç¾¤çš„æ¶æ„ã€‚
ä¸Šé¢ä¿¡æ¯è¯æ˜å·²ç»å¯åŠ¨å®Œæˆï¼Œæˆ‘ä»¬å¯ä»¥æŸ¥çœ‹webç•Œé¢ï¼š[http://localhost:8888/](http://localhost:8888/)ï¼ˆæˆ‘ä¸ªäººçˆ±å¥½ç«¯å£æ˜¯8888ï¼Œé»˜è®¤æ˜¯8080ï¼‰,Â å¦‚ä¸‹ï¼š
![](15776987959455/15777816500228.jpg)

ç›®å‰é›†ç¾¤ç¯å¢ƒå·²ç»å‡†å¤‡å®Œæˆï¼Œæˆ‘ä»¬çœ‹å¦‚æœå°†ä½œä¸šéƒ¨ç½²åˆ°é›†ç¾¤ä¸­ï¼Œä¸€æ¡ç®€å•çš„å‘½ä»¤ï¼Œå¦‚ä¸‹ï¼š

```
bin/flink run -m localhost:8888 -py ~/deploy_demo.py
```
è¿™é‡Œå¦‚æœä½ ä¸æ›´æ”¹ç«¯å£å¯ä»¥ä¸æ·»åŠ `-m` é€‰é¡¹ã€‚å¦‚æœä¸€åˆ‡é¡ºåˆ©ï¼Œä½ ä¼šå¾—åˆ°å¦‚ä¸‹è¾“å‡ºï¼š

```
jincheng:build-target jincheng.sunjc$ bin/flink run -m localhost:8888 -py ~/deploy_demo.py 
Results directory: /var/folders/fp/s5wvp3md31j6v5gjkvqbkhrm0000gp/T/result
Job has been submitted with JobID 3ae7fb8fa0d1867daa8d65fd87ed3bc6
Program execution finished
Job with JobID 3ae7fb8fa0d1867daa8d65fd87ed3bc6 has finished.
Job Runtime: 5389 ms
```
å…¶ä¸­`/var/folders/fp/s5wvp3md31j6v5gjkvqbkhrm0000gp/T/result` ç›®å½•æ˜¯è®¡ç®—ç»“æœç›®å½•ï¼Œæˆ‘ä»¬å¯ä»¥äº§çœ‹ä¸€ä¸‹ï¼Œå¦‚ä¸‹ï¼š

```
jincheng:build-target jincheng.sunjc$  cat /var/folders/fp/s5wvp3md31j6v5gjkvqbkhrm0000gp/T/result
Beijing,110,622890
Guangzhou,20,173980
Shanghai,90,596910
Shenzhen,30,317970
Hangzhou,10,138990
```
åŒæ—¶æˆ‘ä»¬ä¹Ÿå¯ä»¥åœ¨WebUIä¸Šé¢è¿›è¡ŒæŸ¥çœ‹ï¼Œåœ¨å®Œæˆçš„jobåˆ—è¡¨ä¸­ï¼Œæ˜¾ç¤ºå¦‚ä¸‹ï¼š
![](15776987959455/15777853568978.jpg)
åˆ°æ­¤ï¼Œæˆ‘ä»¬å®Œæˆäº†åœ¨Localæ¨¡å¼ï¼Œå…¶å®ä¹Ÿæ˜¯åªæœ‰ä¸€ä¸ªèŠ‚ç‚¹çš„Standaloneæ¨¡å¼ä¸‹å®ŒæˆPyFlinkçš„éƒ¨ç½²ã€‚
æœ€åæˆ‘ä»¬ä¸ºäº†ç»§ç»­ä¸‹é¢çš„æ“ä½œï¼Œè¯·åœæ­¢é›†ç¾¤ï¼š

```
jincheng:build-target jincheng.sunjc$ bin/stop-cluster.sh
Stopping taskexecutor daemon (pid: 45714) on host jincheng.local.
Stopping standalonesession daemon (pid: 45459) on host jincheng.local.
```

# Cluster YARN æ¨¡å¼éƒ¨ç½²
è¿™ä¸ªæ¨¡å¼éƒ¨ç½²ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªYARNç¯å¢ƒï¼Œæˆ‘ä»¬ä¸€åˆ‡ä»ç®€ï¼Œä»¥å•æœºéƒ¨ç½²çš„æ–¹å¼å‡†å¤‡YARNç¯å¢ƒï¼Œç„¶åå†ä¸Flinkè¿›è¡Œé›†æˆã€‚
## å‡†å¤‡YARNç¯å¢ƒ
- å®‰è£…Hadoop

æˆ‘æœ¬æœºæ˜¯macç³»ç»Ÿï¼Œæ‰€ä»¥æˆ‘å·æ‡’ä¸€ä¸‹ç›´æ¥ç”¨brewè¿›è¡Œå®‰è£…ï¼š

```
jincheng:bin jincheng.sunjc$ brew install Hadoop
Updating Homebrew...
==> Auto-updated Homebrew!
Updated 2 taps (homebrew/core and homebrew/cask).
==> Updated Formulae
Python âœ”        doxygen         minio           ntopng          typescript
certbot         libngspice      mitmproxy       ooniprobe
doitlive        minimal-racket  ngspice         openimageio

==> Downloading https://www.apache.org/dyn/closer.cgi?path=hadoop/common/hadoop-
==> Downloading from http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-3.2.1/
######################################################################## 100.0%

ğŸº  /usr/local/Cellar/Hadoop/3.2.1: 22,397 files, 815.6MB, built in 5 minutes 12 seconds
```
å®Œæˆä¹‹åï¼Œæ£€éªŒä¸€ä¸‹hadoopç‰ˆæœ¬ï¼š

```
jincheng:bin jincheng.sunjc$ hadoop version
Hadoop 3.2.1
```
è¶…çº§é¡ºåˆ©ï¼Œhadoopè¢«å®‰è£…åˆ°äº†`/usr/local/Cellar/hadoop/3.2.1/`ç›®å½•ä¸‹ï¼Œ`brew`è¿˜æ˜¯å¾ˆèƒ½æé«˜ç”Ÿäº§åŠ›å•Šï½

- é…ç½®å…ç™»(SSH)

Macç³»ç»Ÿè‡ªå¸¦äº†sshï¼Œæˆ‘ä»¬å¯ä»¥ç®€å•é…ç½®ä¸€ä¸‹å³å¯ï¼Œæˆ‘ä»¬å…ˆæ‰“å¼€è¿œç¨‹ç™»å½•ã€‚ `ç³»ç»Ÿåå¥½è®¾ç½®` -> `å…±äº«` ä¸­ï¼Œå·¦è¾¹å‹¾é€‰ `è¿œç¨‹ç™»å½•` ï¼Œå³è¾¹é€‰æ‹© `ä»…è¿™äº›ç”¨æˆ·` ï¼ˆé€‰æ‹©`æ‰€æœ‰ç”¨æˆ·`æ›´å®½æ¾ï¼‰ï¼Œå¹¶æ·»åŠ å½“å‰ç”¨æˆ·ã€‚

```
jincheng:bin jincheng.sunjc$ whoami
jincheng.sunjc
```
æˆ‘å½“å‰ç”¨æˆ·æ˜¯ `jincheng.sunjc`ã€‚ é…ç½®å›¾å¦‚ä¸‹ï¼š

![](15776987959455/15777878055973.jpg)

ç„¶åç”Ÿäº§è¯ä¹¦ï¼Œå¦‚ä¸‹æ“ä½œï¼š

```
ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
Generating public/private rsa key pair.
/Users/jincheng.sunjc/.ssh/id_rsa already exists.
Overwrite (y/n)? y
Your identification has been saved in /Users/jincheng.sunjc/.ssh/id_rsa.
Your public key has been saved in /Users/jincheng.sunjc/.ssh/id_rsa.pub.
The key fingerprint is:
SHA256:IkjKkOjfMx1fxWlwtQYg8hThph7Xlm9kPutAYFmQR0A jincheng.sunjc@jincheng.local
The key's randomart image is:
+---[RSA 2048]----+
|       ..EB=.o.. |
|..      =.+.+ o .|
|+ .      B.  = o |
|+o .    + o + .  |
|.o. . .+S. * o   |
|  . ..o.= + =    |
|   . + o . . =   |
|      o     o o  |
|            .o   |
+----[SHA256]-----+
```
æ¥ä¸‹æ¥å°†å…¬é’¥è¿½åŠ åˆ°å¦‚ä¸‹æ–‡ä»¶ï¼Œå¹¶ä¿®æ”¹æ–‡ä»¶æƒé™ï¼š

```
jincheng.sunjc$ cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
jincheng.sunjc$ chmod 0600 ~/.ssh/authorized_keys
```
åˆ©ç”¨ssh localhostéªŒè¯ï¼Œçœ‹åˆ° Last login: å­—æ ·ä¸ºsshæˆåŠŸ
 
```
jincheng:~ jincheng.sunjc$ ssh localhost
Password:
Last login: Tue Dec 31 18:26:48 2019 from ::1
```
- è®¾ç½®ç¯å¢ƒå˜é‡

è®¾ç½®JAVA_HOME,HADOOP_HOMEå’ŒHADOOP_CONF_DIRï¼Œ`vi ~/.bashrc`:
  
```
export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_211.jdk/Contents/Home

export HADOOP_HOME=/usr/local/Cellar/hadoop/3.2.1/libexec

export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop
```
NOTE: åç»­æ“ä½œè¦ç¡®ä¿çš„terminalç¯å¢ƒå˜é‡æ˜¯ç”Ÿæ•ˆå“¦ï¼Œ å¦‚æœä¸ç”Ÿæ•ˆå¯ä»¥æ‰§è¡Œ `source ~/.bashrc`ã€‚:)

- ä¿®æ”¹é…ç½®

    1) ä¿®æ”¹core-site.xml
     
```
<configuration>
   <property>
      <name>hadoop.tmp.dir</name>
      <value>/tmp</value>
   </property>
   <property>
      <name>fs.defaultFS</name>
      <value>hdfs://localhost:9000</value>
    </property>
</configuration>
```

    2) ä¿®æ”¹hdfs-site.xml
    
```
<configuration>

    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/tmp/hadoop/name</value>
    </property>
    
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/tmp/hadoop/data</value>
    </property>
    
</configuration>
```

    3) ä¿®æ”¹yarn-site.xml

é…ç½® YARN ä½œä¸ºèµ„æºç®¡ç†æ¡†æ¶ï¼š
```
<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>    
    </property>
    <property>
        <name>yarn.nodemanager.env-whitelist</name>  <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
    </property>
</configuration>
```

ç®€å•çš„é…ç½®å·²ç»å®Œæˆï¼Œæˆ‘ä»¬æ‰§è¡Œä¸€ä¸‹ç®€å•å‘½ä»¤å¯åŠ¨ç¯å¢ƒï¼š

- æ ¼å¼åŒ–æ–‡æ¡£ç³»ç»Ÿï¼š

```
jincheng:libexec jincheng.sunjc$ hadoop namenode -format
...
...
2019-12-31 18:58:53,260 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at jincheng.local/127.0.0.1
************************************************************/

```

- å¯åŠ¨æœåŠ¡ï¼š

æˆ‘ä»¬å…ˆå¯åŠ¨hdfå†å¯åŠ¨yarnï¼Œå¦‚ä¸‹å›¾ï¼š
![](15776987959455/15778389671396.jpg)

Okay,ä¸€åˆ‡é¡ºåˆ©çš„è¯ï¼Œæˆ‘ä»¬ä¼šå¯åŠ¨namenodesï¼Œdatanodesï¼Œresourcemanagerå’Œnodemanagersã€‚æˆ‘ä»¬æœ‰å‡ ä¸ªwebç•Œé¢å¯ä»¥æŸ¥çœ‹ï¼Œå¦‚ä¸‹ï¼š

 1). Overview ç•Œé¢ï¼Œ [http://localhost:9870 ](http://localhost:9870 )å¦‚ä¸‹ï¼š
![](15776987959455/15778373195478.jpg)


 2). NodeManagerç•Œé¢ï¼Œ [http://localhost:8042](http://localhost:8042)ï¼Œå¦‚ä¸‹ï¼š
![-w649](15776987959455/15778373437959.jpg)

 3). ResourceManager ç®¡ç†ç•Œé¢ [http://localhost:8088/](http://localhost:8088/),å¦‚ä¸‹ï¼š
![-w1054](15776987959455/15777972228895.jpg)

ç›®å‰YARNçš„ç¯å¢ƒå·²ç»å‡†å¤‡å®Œæˆï¼Œæˆ‘ä»¬æ¥ä¸‹æ¥çœ‹å¦‚ä½•ä¸Flinkè¿›è¡Œé›†æˆã€‚

## Flinké›†æˆHadoopåŒ…
åˆ‡æ¢åˆ°ç¼–è¯‘ç»“æœç›®å½•ä¸‹`flink/build-target`,å¹¶å°†haddopçš„JARåŒ…æ”¾åˆ°`lib`ç›®å½•ã€‚
åœ¨å®˜ç½‘ä¸‹è½½hadoopåŒ…ï¼Œ

```
cd lib;
curl https://repo.maven.apache.org/maven2/org/apache/flink/flink-shaded-hadoop-2-uber/2.8.3-7.0/flink-shaded-hadoop-2-uber-2.8.3-7.0.jar > flink-shaded-hadoop-2-uber-2.8.3-7.0.jar
```
ä¸‹è½½åï¼Œlibç›®å½•ä¸‹æ–‡ä»¶å¦‚ä¸‹ï¼š
![](15776987959455/15777916683830.jpg)

åˆ°ç°åœ¨ä¸ºæ­¢æˆ‘ä»¬å¯ä»¥æäº¤PyFlinkçš„ä½œä¸šåˆ°ç”±YARNè¿›è¡Œèµ„æºåˆ†é…çš„é›†ç¾¤äº†ã€‚ä½†ä¸ºäº†ç¡®ä¿é›†ç¾¤ä¸Šæœ‰æ­£ç¡®çš„Pythonç¯å¢ƒæˆ‘ä»¬æœ€å¥½æ‰“åŒ…ä¸€ä¸ªPythonç¯å¢ƒåˆ°é›†ç¾¤ä¸Šé¢ã€‚å› ä¸ºå¤§éƒ¨åˆ†æƒ…å†µä¸‹æˆ‘ä»¬æ— æ³•å¾—çŸ¥yarné›†ç¾¤ä¸Šçš„Pythonç‰ˆæœ¬æ˜¯å¦ç¬¦åˆæˆ‘ä»¬çš„è¦æ±‚(Python 3.5+ï¼Œè£…æœ‰apache-beam 2.15.0)ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦æ‰“åŒ…ä¸€ä¸ªç¬¦åˆæ¡ä»¶çš„Pythonç¯å¢ƒï¼Œå¹¶éšjobæ–‡ä»¶æäº¤åˆ°yarné›†ç¾¤ä¸Šã€‚

## æ‰“åŒ…Pythonç¯å¢ƒ
å†æ¬¡æ£€æŸ¥ä¸€ä¸‹å½“å‰Pythonçš„ç‰ˆæœ¬æ˜¯å¦3.5+ï¼Œå¦‚ä¸‹ï¼š
```
jincheng:lib jincheng.sunjc$ Python
Python 3.7.6 (default, Dec 31 2019, 09:48:30) 
```
ç”±äºè¿™ä¸ªPythonç¯å¢ƒæ˜¯ç”¨äºé›†ç¾¤çš„ï¼Œæ‰€ä»¥æ‰“åŒ…æ—¶çš„ç³»ç»Ÿéœ€è¦å’Œé›†ç¾¤ä¸€è‡´ã€‚å¦‚æœä¸ä¸€è‡´ï¼Œæ¯”å¦‚é›†ç¾¤æ˜¯linuxè€Œæœ¬æœºæ˜¯macï¼Œæˆ‘ä»¬éœ€è¦åœ¨è™šæ‹Ÿæœºæˆ–è€…dockerä¸­æ‰“åŒ…ã€‚ä»¥ä¸‹åˆ—å‡ºä¸¤ç§æƒ…å†µçš„ç¤ºèŒƒæ–¹æ³•ï¼Œè¯»è€…æ ¹æ®éœ€æ±‚é€‰æ‹©ä¸€ç§å³å¯ã€‚

### æœ¬åœ°æ‰“åŒ…ï¼ˆé›†ç¾¤å’Œæœ¬æœºæ“ä½œç³»ç»Ÿä¸€è‡´æ—¶ï¼‰
å¦‚æœé›†ç¾¤æ‰€åœ¨æœºå™¨çš„æ“ä½œç³»ç»Ÿå’Œæœ¬åœ°ä¸€è‡´ï¼ˆéƒ½æ˜¯macæˆ–è€…éƒ½æ˜¯linuxï¼‰ï¼Œç›´æ¥é€šè¿‡virtualenvæ‰“åŒ…ä¸€ä¸ªç¬¦åˆæ¡ä»¶çš„Pythonç¯å¢ƒï¼š
- å®‰è£…virtualenv
ä½¿ç”¨`python -m pip install virtualenv` è¿›è¡Œå®‰è£…å¦‚ä¸‹ï¼š

```
jincheng:tmp jincheng.sunjc$ python -m pip install virtualenv
Collecting virtualenv
  Downloading https://files.Pythonhosted.org/packages/05/f1/2e07e8ca50e047b9cc9ad56cf4291f4e041fa73207d000a095fe478abf84/virtualenv-16.7.9-py2.py3-none-any.whl (3.4MB)
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.4MB 2.0MB/s 
Installing collected packages: virtualenv
Successfully installed virtualenv-16.7.9
```
æˆ‘æœ¬åœ°ç¯å¢ƒå·²ç»æˆåŠŸå®‰è£…ã€‚

- åˆ›å»ºPythonç¯å¢ƒ
ç”¨virtualenvä»¥always-copyæ–¹å¼å»ºç«‹ä¸€ä¸ªå…¨æ–°çš„Pythonç¯å¢ƒï¼Œåå­—éšæ„ï¼Œä»¥venvä¸ºä¾‹ï¼Œ`virtualenv --always-copy venv`:

```
jincheng:tmp jincheng.sunjc$ virtualenv --always-copy venv
Using base prefix '/usr/local/Cellar/Python/3.7.6/Frameworks/Python.framework/Versions/3.7'
New Python executable in /Users/jincheng.sunjc/temp/hadoop/tmp/venv/bin/Python3.7
Also creating executable in /Users/jincheng.sunjc/temp/hadoop/tmp/venv/bin/Python
Installing setuptools, pip, wheel...
done.
```
- åœ¨æ–°ç¯å¢ƒä¸­å®‰è£…apache-beam 2.15.0
ä½¿ç”¨`venv/bin/pip install apache-beam==2.15.0`è¿›è¡Œå®‰è£…ï¼š

```
jincheng:tmp jincheng.sunjc$ venv/bin/pip install apache-beam==2.15.0
Collecting apache-beam==2.15.0
...
...
Successfully installed apache-beam-2.15.0 avro-Python3-1.9.1 certifi-2019.11.28 chardet-3.0.4 crcmod-1.7 dill-0.2.9 docopt-0.6.2 fastavro-0.21.24 future-0.18.2 grpcio-1.26.0 hdfs-2.5.8 httplib2-0.12.0 idna-2.8 mock-2.0.0 numpy-1.18.0 oauth2client-3.0.0 pbr-5.4.4 protobuf-3.11.2 pyarrow-0.14.1 pyasn1-0.4.8 pyasn1-modules-0.2.7 pydot-1.4.1 pymongo-3.10.0 pyparsing-2.4.6 pytz-2019.3 pyyaml-3.13 requests-2.22.0 rsa-4.0 six-1.13.0 urllib3-1.25.7
```
ä¸Šé¢ä¿¡æ¯å·²ç»è¯´æ˜æˆ‘ä»¬æˆåŠŸçš„åœ¨Pythonç¯å¢ƒä¸­å®‰è£…äº†apache-beam==2.15.0ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬æ‰“åŒ…Pythonç¯å¢ƒã€‚
- æ‰“åŒ…Pythonç¯å¢ƒ
 æˆ‘ä»¬å°†Pythonæ‰“åŒ…æˆzipæ–‡ä»¶ï¼Œ`zip -r venv.zip venv` å¦‚ä¸‹ï¼š
 
```
zip -r venv.zip venv
...
...
  adding: venv/lib/Python3.7/re.py (deflated 68%)
  adding: venv/lib/Python3.7/struct.py (deflated 46%)
  adding: venv/lib/Python3.7/sre_parse.py (deflated 80%)
  adding: venv/lib/Python3.7/abc.py (deflated 72%)
  adding: venv/lib/Python3.7/_bootlocale.py (deflated 63%)
```
æŸ¥çœ‹ä¸€ä¸‹zipå¤§å°ï¼š

```
jincheng:tmp jincheng.sunjc$ du -sh venv.zip 
 81M	venv.zip
```
è¿™ä¸ªå¤§å°å®åœ¨å¤ªå¤§äº†ï¼Œæ ¸å¿ƒé—®é¢˜æ˜¯Beamçš„åŒ…éå¸¸å¤§ï¼Œåé¢æˆ‘ä¼šæŒç»­åœ¨Beamç¤¾åŒºæå‡ºä¼˜åŒ–å»ºè®®ã€‚æˆ‘ä»¬å…ˆå¿ä¸€ä¸‹:(ã€‚

### Dockerä¸­æ‰“åŒ…ï¼ˆæ¯”å¦‚é›†ç¾¤ä¸ºlinuxï¼Œæœ¬æœºä¸ºmacæ—¶ï¼‰
æˆ‘ä»¬é€‰æ‹©åœ¨dockerä¸­æ‰“åŒ…ï¼Œå¯ä»¥ä»ä»¥ä¸‹é“¾æ¥ä¸‹è½½æœ€æ–°ç‰ˆdockerå¹¶å®‰è£…ï¼š
[https://download.docker.com/mac/stable/Docker.dmg](https://download.docker.com/mac/stable/Docker.dmg)å®‰è£…å®Œæ¯•åé‡å¯ç»ˆç«¯ï¼Œæ‰§è¡Œ`docker version`ç¡®è®¤dockerå®‰è£…æˆåŠŸï¼š

```
jincheng:tmp jincheng.sunjc$ docker version
Client: Docker Engine - Community
 Version:           19.03.4
 API version:       1.40
 Go version:        go1.12.10
 Git commit:        9013bf5
 Built:             Thu Oct 17 23:44:48 2019
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.4
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.10
  Git commit:       9013bf5
  Built:            Thu Oct 17 23:50:38 2019
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.10
  GitCommit:        b34a5c8af56e510852c35414db4c1f4fa6172339
 runc:
  Version:          1.0.0-rc8+dev
  GitCommit:        3e425f80a8c931f88e6d94a8c831b9d5aa481657
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

- å¯åŠ¨å®¹å™¨
æˆ‘ä»¬å¯åŠ¨ä¸€ä¸ªPython 3.7ç‰ˆæœ¬çš„å®¹å™¨å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡å¯åŠ¨å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´æ¥æ‹‰å–é•œåƒï¼š
`docker run -it Python:3.7 /bin/bash`, å¦‚ä¸‹ï¼š

```
jincheng:libexec jincheng.sunjc$  docker run -it Python:3.7 /bin/bash
Unable to find image 'Python:3.7' locally
3.7: Pulling from library/Python
8f0fdd3eaac0: Pull complete 
d918eaefd9de: Pull complete 
43bf3e3107f5: Pull complete 
27622921edb2: Pull complete 
dcfa0aa1ae2c: Pull complete 
bf6840af9e70: Pull complete 
167665d59281: Pull complete 
ffc544588c7f: Pull complete 
4ebe99df65fe: Pull complete 
Digest: sha256:40d615d7617f0f3b54614fd228d41a891949b988ae2b452c0aaac5bee924888d
Status: Downloaded newer image for Python:3.7
```

- å®¹å™¨ä¸­å®‰è£…virtualenv
æˆ‘ä»¬åœ¨åˆšæ‰å¯åŠ¨çš„å®¹å™¨ä¸­å®‰è£…virtualenvï¼Œ `pip install virtualenv`,å¦‚ä¸‹ï¼š
```
root@1b48d2b526ae:/# pip install virtualenv
Collecting virtualenv
  Downloading https://files.Pythonhosted.org/packages/05/f1/2e07e8ca50e047b9cc9ad56cf4291f4e041fa73207d000a095fe478abf84/virtualenv-16.7.9-py2.py3-none-any.whl (3.4MB)
     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.4MB 2.0MB/s 
Installing collected packages: virtualenv
Successfully installed virtualenv-16.7.9
root@1b48d2b526ae:/# 
```

- åˆ›å»ºPythonç¯å¢ƒ
ä»¥always copyæ–¹å¼å»ºç«‹ä¸€ä¸ªå…¨æ–°çš„Pythonç¯å¢ƒï¼Œåå­—éšæ„ï¼Œä»¥venvä¸ºä¾‹ï¼Œ`virtualenv --always-copy venv`, å¦‚ä¸‹ï¼š


```
root@1b48d2b526ae:/# virtualenv --always-copy venv
Using base prefix '/usr/local'
New Python executable in /venv/bin/Python
Installing setuptools, pip, wheel...
done.
root@1b48d2b526ae:/# 
```

- å®‰è£…Apache Beam
 åœ¨æ–°çš„Pythonç¯å¢ƒä¸­å®‰è£…apache-beam 2.15.0ï¼Œ`venv/bin/pip install apache-beam==2.15.0`,å¦‚ä¸‹ï¼š
 
```
root@1b48d2b526ae:/# venv/bin/pip install apache-beam==2.15.0
Collecting apache-beam==2.15.0
...
...
Successfully installed apache-beam-2.15.0 avro-Python3-1.9.1 certifi-2019.11.28 chardet-3.0.4 crcmod-1.7 dill-0.2.9 docopt-0.6.2 fastavro-0.21.24 future-0.18.2 grpcio-1.26.0 hdfs-2.5.8 httplib2-0.12.0 idna-2.8 mock-2.0.0 numpy-1.18.0 oauth2client-3.0.0 pbr-5.4.4 protobuf-3.11.2 pyarrow-0.14.1 pyasn1-0.4.8 pyasn1-modules-0.2.7 pydot-1.4.1 pymongo-3.10.0 pyparsing-2.4.6 pytz-2019.3 pyyaml-3.13 requests-2.22.0 rsa-4.0 six-1.13.0 urllib3-1.25.7
```
- æŸ¥çœ‹dockerä¸­çš„Pythonç¯å¢ƒ
ç”¨`exit`å‘½ä»¤é€€å‡ºå®¹å™¨ï¼Œç”¨`docker ps -a`æ‰¾åˆ°dockerå®¹å™¨çš„idï¼Œç”¨äºæ‹·è´æ–‡ä»¶,å¦‚ä¸‹ï¼š

```
root@1b48d2b526ae:/# exit
exit
jincheng:libexec jincheng.sunjc$ docker ps -a
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                     PORTS               NAMES
1b48d2b526ae        Python:3.7          "/bin/bash"         7 minutes ago       Exited (0) 8 seconds ago                       elated_visvesvaraya
```
ç”±äºåˆšåˆšç»“æŸï¼Œä¸€èˆ¬æ¥è¯´æ˜¯åˆ—è¡¨ä¸­çš„ç¬¬ä¸€æ¡ï¼Œå¯ä»¥æ ¹æ®å®¹å™¨çš„é•œåƒåPython:3.7æ¥åˆ†è¾¨ã€‚æˆ‘ä»¬è®°ä¸‹æœ€å·¦è¾¹çš„å®¹å™¨IDã€‚å¦‚ä¸Šæ˜¯`1b48d2b526ae`ã€‚

- æ‰“åŒ…Pythonç¯å¢ƒ
 ä»å°†å®¹å™¨ä¸­çš„Pythonç¯å¢ƒæ‹·è´å‡ºæ¥ï¼Œæˆ‘ä»¬åˆ‡æ¢åˆ°`flink/build-target`å½•ä¸‹ï¼Œæ‹·è´ `docker cp 1b48d2b526ae:/venv ./`å¹¶æ‰“åŒ…`zip -r venv.zip venv`ã€‚
 æœ€ç»ˆ`flink/build-target`å½•ä¸‹ç”Ÿæˆ`venv.zip`ã€‚
 

## éƒ¨ç½²ä½œä¸š
ç»ˆäºåˆ°éƒ¨ç½²ä½œä¸šçš„ç¯èŠ‚äº†:), flink on yarnæ”¯æŒä¸¤ç§æ¨¡å¼ï¼Œper-jobå’Œsessionã€‚per-jobæ¨¡å¼åœ¨æäº¤jobæ—¶ä¼šä¸ºæ¯ä¸ªjobå•ç‹¬èµ·ä¸€ä¸ªflinké›†ç¾¤ï¼Œsessionæ¨¡å¼å…ˆåœ¨yarnä¸Šèµ·ä¸€ä¸ªflinké›†ç¾¤ï¼Œä¹‹åæäº¤jobéƒ½æäº¤åˆ°è¿™ä¸ªflinké›†ç¾¤ã€‚

### Pre-Job æ¨¡å¼éƒ¨ç½²ä½œä¸š
æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œä»¥Pre-Jobæ¨¡å¼éƒ¨ç½²PyFlinkä½œä¸šï¼š
`bin/flink run -m yarn-cluster -pyarch venv.zip -pyexec venv.zip/venv/bin/Python -py deploy_demo.py`,å¦‚ä¸‹ï¼š

```
jincheng:build-target jincheng.sunjc$ bin/flink run -m yarn-cluster -pyarch venv.zip -pyexec venv.zip/venv/bin/Python -py deploy_demo.py
2020-01-02 13:04:52,889 WARN  org.apache.flink.yarn.cli.FlinkYarnSessionCli                 - The configuration directory ('/Users/jincheng.sunjc/blog/demo_dev/flink/flink-dist/target/flink-1.10-SNAPSHOT-bin/flink-1.10-SNAPSHOT/conf') already contains a LOG4J config file.If you want to use logback, then please delete or rename the log configuration file.
2020-01-02 13:04:52,889 WARN  org.apache.flink.yarn.cli.FlinkYarnSessionCli                 - The configuration directory ('/Users/jincheng.sunjc/blog/demo_dev/flink/flink-dist/target/flink-1.10-SNAPSHOT-bin/flink-1.10-SNAPSHOT/conf') already contains a LOG4J config file.If you want to use logback, then please delete or rename the log configuration file.
Results directory: /var/folders/fp/s5wvp3md31j6v5gjkvqbkhrm0000gp/T/result
2020-01-02 13:04:55,945 INFO  org.apache.hadoop.yarn.client.RMProxy                         - Connecting to ResourceManager at /0.0.0.0:8032
2020-01-02 13:04:56,049 INFO  org.apache.flink.yarn.YarnClusterDescriptor                   - No path for the flink jar passed. Using the location of class org.apache.flink.yarn.YarnClusterDescriptor to locate the jar
2020-01-02 13:05:01,153 WARN  org.apache.flink.yarn.YarnClusterDescriptor                   - Neither the HADOOP_CONF_DIR nor the YARN_CONF_DIR environment variable is set. The Flink YARN Client needs one of these to be set to properly load the Hadoop configuration for accessing YARN.
2020-01-02 13:05:01,177 INFO  org.apache.flink.yarn.YarnClusterDescriptor                   - Cluster specification: ClusterSpecification{masterMemoryMB=1024, taskManagerMemoryMB=1024, numberTaskManagers=1, slotsPerTaskManager=1}
2020-01-02 13:05:01,294 WARN  org.apache.flink.yarn.YarnClusterDescriptor                   - The file system scheme is 'file'. This indicates that the specified Hadoop configuration path is wrong and the system is using the default Hadoop configuration values.The Flink YARN client needs to store its files in a distributed file system
2020-01-02 13:05:02,600 INFO  org.apache.flink.yarn.YarnClusterDescriptor                   - Submitting application master application_1577936885434_0004
2020-01-02 13:05:02,971 INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl         - Submitted application application_1577936885434_0004
2020-01-02 13:05:02,972 INFO  org.apache.flink.yarn.YarnClusterDescriptor                   - Waiting for the cluster to be allocated
2020-01-02 13:05:02,975 INFO  org.apache.flink.yarn.YarnClusterDescriptor                   - Deploying cluster, current state ACCEPTED
2020-01-02 13:05:23,138 INFO  org.apache.flink.yarn.YarnClusterDescriptor                   - YARN application has been deployed successfully.
2020-01-02 13:05:23,140 INFO  org.apache.flink.yarn.YarnClusterDescriptor                   - Found Web Interface localhost:61616 of application 'application_1577936885434_0004'.
Job has been submitted with JobID a41d82194a500809fd715da8f29894a0
Program execution finished
Job with JobID a41d82194a500809fd715da8f29894a0 has finished.
Job Runtime: 35576 ms
```
ä¸Šé¢ä¿¡æ¯å·²ç»æ˜¾ç¤ºè¿è¡Œå®Œæˆï¼Œåœ¨Webç•Œé¢å¯ä»¥çœ‹åˆ°ä½œä¸šçŠ¶æ€ï¼š
![](15776987959455/15779417223687.jpg)

æˆ‘ä»¬å†æ£€éªŒä¸€ä¸‹è®¡ç®—ç»“æœ`cat /var/folders/fp/s5wvp3md31j6v5gjkvqbkhrm0000gp/T/result`ï¼š
![](15776987959455/15779417681405.jpg)

åˆ°è¿™é‡Œï¼Œæˆ‘ä»¬ä»¥Pre-Jobçš„æ–¹å¼æˆåŠŸéƒ¨ç½²äº†PyFlinkçš„ä½œä¸šï¼ç›¸æ¯”æäº¤åˆ°æœ¬åœ°Standaloneé›†ç¾¤ï¼Œå¤šäº†ä¸‰ä¸ªå‚æ•°ï¼Œæˆ‘ä»¬ç®€å•è¯´æ˜å¦‚ä¸‹ï¼š

| å‚æ•°                               | è¯´æ˜                                                  |
|----------------------------------|-----------------------------------------------------|
| -m yarn-cluster                  | ä»¥Per-Jobæ¨¡å¼éƒ¨ç½²åˆ°yarné›†ç¾¤                                 |
| -pyarch venv.zip                 | å°†å½“å‰ç›®å½•ä¸‹çš„venv.zipä¸Šä¼ åˆ°yarné›†ç¾¤                            |
| -pyexec venv.zip/venv/bin/Python | æŒ‡å®švenv.zipä¸­çš„Pythonè§£é‡Šå™¨æ¥æ‰§è¡ŒPython UDFï¼Œè·¯å¾„éœ€è¦å’ŒzipåŒ…å†…éƒ¨ç»“æ„ä¸€è‡´ã€‚ |

### Session æ¨¡å¼éƒ¨ç½²ä½œä¸š
ä»¥Sessionæ¨¡å¼éƒ¨ç½²ä½œä¸šä¹Ÿéå¸¸ç®€å•ï¼Œæˆ‘ä»¬å®é™…æ“ä½œä¸€ä¸‹ï¼š

```
jincheng:build-target jincheng.sunjc$ bin/yarn-session.sh 
2020-01-02 13:58:53,049 INFO  org.apache.flink.configuration.GlobalConfiguration            - Loading configuration property: jobmanager.rpc.address, localhost
2020-01-02 13:58:53,050 INFO  org.apache.flink.configuration.GlobalConfiguration            - Loading configuration property: jobmanager.rpc.port, 6123
2020-01-02 13:58:53,050 INFO  org.apache.flink.configuration.GlobalConfiguration            - Loading configuration property: jobmanager.heap.size, 1024m
2020-01-02 13:58:53,050 INFO  org.apache.flink.configuration.GlobalConfiguration            - Loading configuration property: taskmanager.memory.process.size, 1024m
2020-01-02 13:58:53,050 INFO  org.apache.flink.configuration.GlobalConfiguration            - Loading configuration property: taskmanager.numberOfTaskSlots, 1
2020-01-02 13:58:53,050 INFO  org.apache.flink.configuration.GlobalConfiguration            - Loading configuration property: parallelism.default, 1
2020-01-02 13:58:53,051 INFO  org.apache.flink.configuration.GlobalConfiguration            - Loading configuration property: jobmanager.execution.failover-strategy, region
2020-01-02 13:58:53,413 WARN  org.apache.hadoop.util.NativeCodeLoader                       - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2020-01-02 13:58:53,476 INFO  org.apache.flink.runtime.security.modules.HadoopModule        - Hadoop user set to jincheng.sunjc (auth:SIMPLE)
2020-01-02 13:58:53,509 INFO  org.apache.flink.runtime.security.modules.JaasModule          - Jaas file will be created as /var/folders/fp/s5wvp3md31j6v5gjkvqbkhrm0000gp/T/jaas-3848984206030141476.conf.
2020-01-02 13:58:53,521 WARN  org.apache.flink.yarn.cli.FlinkYarnSessionCli                 - The configuration directory ('/Users/jincheng.sunjc/blog/demo_dev/flink/flink-dist/target/flink-1.10-SNAPSHOT-bin/flink-1.10-SNAPSHOT/conf') already contains a LOG4J config file.If you want to use logback, then please delete or rename the log configuration file.
2020-01-02 13:58:53,562 INFO  org.apache.hadoop.yarn.client.RMProxy                         - Connecting to ResourceManager at /0.0.0.0:8032
2020-01-02 13:58:58,803 WARN  org.apache.flink.yarn.YarnClusterDescriptor                   - Neither the HADOOP_CONF_DIR nor the YARN_CONF_DIR environment variable is set. The Flink YARN Client needs one of these to be set to properly load the Hadoop configuration for accessing YARN.
2020-01-02 13:58:58,824 INFO  org.apache.flink.yarn.YarnClusterDescriptor                   - Cluster specification: ClusterSpecification{masterMemoryMB=1024, taskManagerMemoryMB=1024, numberTaskManagers=1, slotsPerTaskManager=1}
2020-01-02 13:59:03,975 WARN  org.apache.flink.yarn.YarnClusterDescriptor                   - The file system scheme is 'file'. This indicates that the specified Hadoop configuration path is wrong and the system is using the default Hadoop configuration values.The Flink YARN client needs to store its files in a distributed file system
2020-01-02 13:59:04,779 INFO  org.apache.flink.yarn.YarnClusterDescriptor                   - Submitting application master application_1577936885434_0005
2020-01-02 13:59:04,799 INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl         - Submitted application application_1577936885434_0005
2020-01-02 13:59:04,799 INFO  org.apache.flink.yarn.YarnClusterDescriptor                   - Waiting for the cluster to be allocated
2020-01-02 13:59:04,801 INFO  org.apache.flink.yarn.YarnClusterDescriptor                   - Deploying cluster, current state ACCEPTED
2020-01-02 13:59:24,711 INFO  org.apache.flink.yarn.YarnClusterDescriptor                   - YARN application has been deployed successfully.
2020-01-02 13:59:24,713 INFO  org.apache.flink.yarn.YarnClusterDescriptor                   - Found Web Interface localhost:62247 of application 'application_1577936885434_0005'.
JobManager Web Interface: http://localhost:62247

```
æ‰§è¡ŒæˆåŠŸåä¸ä¼šè¿”å›ï¼Œä½†ä¼šå¯åŠ¨ä¸€ä¸ªJoBManager Webï¼Œåœ°å€å¦‚ä¸Š`http://localhost:62247`ï¼Œå¯å¤åˆ¶åˆ°æµè§ˆå™¨æŸ¥çœ‹:
![](15776987959455/15779449909178.jpg)


æˆ‘ä»¬å¯ä»¥ä¿®æ”¹conf/flink-conf.yamlä¸­çš„é…ç½®å‚æ•°ã€‚å¦‚æœè¦æ›´æ”¹æŸäº›å†…å®¹ï¼Œè¯·å‚è€ƒ[å®˜æ–¹æ–‡æ¡£](https://ci.apache.org/projects/flink/flink-docs-release-1.10/ops/config.html)ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬æäº¤ä½œä¸šï¼Œé¦–å…ˆæŒ‰ç»„åˆé”®Ctrl+Zå°†yarn-session.shè¿›ç¨‹åˆ‡æ¢åˆ°åå°ï¼Œå¹¶æ‰§è¡ŒbgæŒ‡ä»¤è®©å…¶åœ¨åå°ç»§ç»­æ‰§è¡Œ, ç„¶åæ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œå³å¯å‘Sessionæ¨¡å¼çš„flinké›†ç¾¤æäº¤job `bin/flink run -m yarn-cluster -pyarch venv.zip -pyexec venv.zip/venv/bin/Python -py deploy_demo.py`ï¼š


```
jincheng:build-target jincheng.sunjc$ bin/flink run -pyarch venv.zip -pyexec venv.zip/venv/bin/Python -py deploy_demo.py

2020-01-02 14:10:48,285 INFO  org.apache.flink.yarn.YarnClusterDescriptor                   - Found Web Interface localhost:62247 of application 'application_1577936885434_0005'.
Job has been submitted with JobID bea33b7aa07c0f62153ab5f6e134b6bf
Program execution finished
Job with JobID bea33b7aa07c0f62153ab5f6e134b6bf has finished.
Job Runtime: 34405 ms
```
å¦‚æœåœ¨æ‰“å°`finished`ä¹‹å‰æŸ¥çœ‹ä¹‹å‰çš„webé¡µé¢ï¼Œæˆ‘ä»¬ä¼šå‘ç°Sessioné›†ç¾¤ä¼šæœ‰ä¸€ä¸ªæ­£ç¡®è¿è¡Œçš„ä½œä¸šï¼Œå¦‚ä¸‹ï¼š
![](15776987959455/15779454827330.jpg)
å¦‚æœå·²ç»è¿è¡Œå®Œæˆï¼Œé‚£ä¹ˆæˆ‘ä»¬åº”è¯¥ä¼šçœ‹åˆ°çŠ¶æ€ä¹Ÿå˜æˆç»“æŸï¼š
![](15776987959455/15779456315383.jpg)

ç›¸æ¯”per jobæ¨¡å¼æäº¤ï¼Œå°‘äº†â€-mâ€å‚æ•°ã€‚å› ä¸ºä¹‹å‰å·²ç»å¯åŠ¨äº†yarn-session.shï¼Œæ‰€ä»¥flinké»˜è®¤ä¼šå‘yarn-session.shå¯åŠ¨çš„é›†ç¾¤ä¸Šæäº¤jobã€‚æ‰§è¡Œå®Œæ¯•åï¼Œåˆ«å¿˜äº†å…³é—­yarn-session.shï¼ˆsession æ¨¡å¼ï¼‰ï¼šå…ˆå°†yarn-session.shè°ƒåˆ°å‰å°ï¼Œæ‰§è¡Œ`fg`,ç„¶ååœ¨å†æŒ‰Ctrl+Cç»“æŸè¿›ç¨‹æˆ–è€…æ‰§è¡Œ`stop`ï¼Œç»“æŸæ—¶yarnä¸Šçš„é›†ç¾¤ä¹Ÿä¼šè¢«å…³é—­ã€‚

# Docker æ¨¡å¼éƒ¨ç½²
æˆ‘ä»¬è¿˜å¯ä»¥å°†Flink Python jobæ‰“åŒ…æˆdockeré•œåƒï¼Œç„¶åä½¿ç”¨docker-composeæˆ–è€…Kuberneteséƒ¨ç½²æ‰§è¡Œï¼Œç”±äºç°åœ¨çš„dockeré•œåƒæ‰“åŒ…å·¥å…·å¹¶æ²¡æœ‰å®Œç¾æ”¯æŒè¿è¡ŒPython UDFï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦å¾€é‡Œé¢æ·»åŠ ä¸€äº›é¢å¤–çš„æ–‡ä»¶ã€‚é¦–å…ˆæ˜¯ä¸€ä¸ªä»…åŒ…å«PythonDriverç±»çš„jaråŒ…. æˆ‘ä»¬åœ¨`build-target`ç›®å½•ä¸‹æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ï¼š

```
jincheng:build-target jincheng.sunjc$ mkdir temp
jincheng:build-target jincheng.sunjc$ cd temp
jincheng:temp jincheng.sunjc$ unzip ../opt/flink-Python_2.11-1.10-SNAPSHOT.jar org/apache/flink/client/Python/PythonDriver.class
Archive:  ../opt/flink-Python_2.11-1.10-SNAPSHOT.jar
  inflating: org/apache/flink/client/Python/PythonDriver.class 
```
è§£å‹ä¹‹åï¼Œæˆ‘ä»¬åœ¨è¿›è¡Œå‹ç¼©æ‰“åŒ…ï¼š

```
jincheng:temp jincheng.sunjc$ zip Python-driver.jar org/apache/flink/client/Python/PythonDriver.class
  adding: org/apache/flink/client/Python/PythonDriver.class (deflated 56%)
```
![](15776987959455/15779465411786.jpg)
æˆ‘ä»¬å¾—åˆ°`Python-driver.jar`ã€‚ç„¶åä¸‹è½½ä¸€ä¸ªpyArrowçš„å®‰è£…æ–‡ä»¶(æˆ‘å‡†å¤‡äº†ä¸€ä¸ªå¤§å®¶ä¸‹è½½ç›´æ¥ä½¿ç”¨å³å¯ [pyarrow-0.12.0a0-cp36-cp36m-linux_x86_64.whl](https://github.com/sunjincheng121/enjoyment.code/blob/master/share_resource/pyarrow-0.12.0a0-cp36-cp36m-linux_x86_64.whl)ã€‚æ‰§è¡Œä»¥ä¸‹å‘½ä»¤æ„å»ºDockeré•œåƒï¼Œéœ€è¦ä½œä¸ºartifactså¼•å…¥çš„æ–‡ä»¶æœ‰ä½œä¸šæ–‡ä»¶ï¼ŒPython-driverçš„jaråŒ…å’Œpyarrowå®‰è£…æ–‡ä»¶,`./build.sh --job-artifacts ~/deploy_demo.py,Python-driver.jar,pyarrow-0.12.0a0-cp36-cp36m-linux_x86_64.whl --with-Python3 --from-local-dist`(è¿›å…¥`flink/flink-container/docker`ç›®å½•)

```
jincheng:docker jincheng.sunjc$ ./build.sh --job-artifacts ~/deploy_demo.py,Python-driver.jar,pyarrow-0.12.0a0-cp36-cp36m-linux_x86_64.whl --with-Python3 --from-local-dist
Using flink dist: ../../flink-dist/target/flink-*-bin
a .
a ./flink-1.10-SNAPSHOT
a ./flink-1.10-SNAPSHOT/temp
...
...
Removing intermediate container a0558bbcbdd1
 ---> 00ecda6117b7
Successfully built 00ecda6117b7
Successfully tagged flink-job:latest
```
æ„å»ºDockeré•œåƒéœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚æ„å»ºå®Œæ¯•ä¹‹åï¼Œå¯ä»¥è¾“å…¥docker imageså‘½ä»¤åœ¨é•œåƒåˆ—è¡¨ä¸­æ‰¾åˆ°æ„å»ºç»“æœ`docker images
`ï¼š
![-w765](15776987959455/15779503938890.jpg)
ç„¶åæˆ‘ä»¬åœ¨æ„å»ºå¥½çš„é•œåƒåŸºç¡€ä¸Šå®‰è£…å¥½Python udfæ‰€éœ€ä¾èµ–ï¼Œå¹¶åˆ é™¤è¿‡ç¨‹ä¸­äº§ç”Ÿçš„ä¸´æ—¶æ–‡ä»¶ï¼š
- å¯åŠ¨dockerå®¹å™¨
`docker run -it --user root --entrypoint /bin/bash --name flink-job-container flink-job`
- å®‰è£…ä¸€äº›ä¾èµ–
`apk add --no-cache g++ Python3-dev musl-dev`
- å®‰è£…PyArrow
`python -m pip3 install /opt/artifacts/pyarrow-0.12.0a0-cp36-cp36m-linux_x86_64.whl`

- å®‰è£…Apache Beam
`python -m pip3 install apache-beam==2.15.0`

- åˆ é™¤ä¸´æ—¶æ–‡ä»¶
`rm -rf /root/.cache/pip`

æ‰§è¡Œå®Œå¦‚ä¸Šå‘½ä»¤æˆ‘å¯ä»¥æ‰§è¡Œ`exit`é€€å‡ºå®¹å™¨äº†ï¼Œç„¶åæŠŠè¿™ä¸ªå®¹å™¨æäº¤ä¸ºæ–°çš„flink-jobé•œåƒ`docker commit -c 'CMD ["--help"]' -c "USER flink" -c 'ENTRYPOINT ["/docker-entrypoint.sh"]' flink-job-container flink-job:latest 
`ï¼š

```
jincheng:docker jincheng.sunjc$ docker commit -c 'CMD ["--help"]' -c "USER flink" -c 'ENTRYPOINT ["/docker-entrypoint.sh"]' flink-job-container flink-job:latest 
sha256:0740a635e2b0342ddf776f33692df263ebf0437d6373f156821f4dd044ad648b
```
åˆ°è¿™é‡ŒåŒ…å«Python UDF ä½œä¸šçš„Dockeré•œåƒå°±åˆ¶ä½œå¥½äº†ï¼Œè¿™ä¸ªDockeré•œåƒæ—¢å¯ä»¥ä»¥docker-composeä½¿ç”¨ï¼Œä¹Ÿå¯ä»¥ç»“åˆkubernetesä¸­ä½¿ç”¨ã€‚

æˆ‘ä»¬ä»¥ä½¿ç”¨docker-composeæ‰§è¡Œä¸ºä¾‹ï¼Œmacç‰ˆdockerè‡ªå¸¦docker-composeï¼Œç”¨æˆ·å¯ä»¥ç›´æ¥ä½¿ç”¨ï¼Œåœ¨`flink/flink-container/docker`ç›®å½•ä¸‹ï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯åŠ¨ä½œä¸š,`FLINK_JOB=org.apache.flink.client.Python.PythonDriver FLINK_JOB_ARGUMENTS="-py /opt/artifacts/deploy_demo.py" docker-compose up`:


```
jincheng:docker jincheng.sunjc$ FLINK_JOB=org.apache.flink.client.Python.PythonDriver FLINK_JOB_ARGUMENTS="-py /opt/artifacts/deploy_demo.py" docker-compose up
WARNING: The SAVEPOINT_OPTIONS variable is not set. Defaulting to a blank string.
Recreating docker_job-cluster_1 ... done
Starting docker_taskmanager_1   ... done
Attaching to docker_taskmanager_1, docker_job-cluster_1
taskmanager_1  | Starting the task-manager
job-cluster_1  | Starting the job-cluster
...
...
job-cluster_1  | 2020-01-02 08:35:03,796 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint         - Terminating cluster entrypoint process StandaloneJobClusterEntryPoint with exit code 0.
docker_job-cluster_1 exited with code 0
```
åœ¨logä¸­å‡ºç°â€œdocker_job-cluster_1 exited with code 0â€è¡¨ç¤ºjobå·²æ‰§è¡ŒæˆåŠŸï¼ŒJobManagerå·²ç»é€€å‡ºã€‚TaskManagerè¿˜éœ€è¦è¾ƒé•¿çš„æ—¶é—´ç­‰å¾…è¶…æ—¶åæ‰ä¼šé€€å‡ºï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥æŒ‰å¿«æ·é”®Ctrl+Cæå‰é€€å‡ºã€‚

æŸ¥çœ‹æ‰§è¡Œç»“æœï¼Œå¯ä»¥ä»TaskManagerçš„å®¹å™¨ä¸­å°†ç»“æœæ–‡ä»¶æ‹·è´å‡ºæ¥æŸ¥çœ‹,æ‰§è¡Œ `docker cp docker_taskmanager_1:/tmp/result ./; cat result `
![](15776987959455/15779542617667.jpg)

Okay, åˆ°è¿™é‡Œæœ¬ç¯‡è¦ä¸å¤§å®¶åˆ†äº«çš„å†…å®¹å·²ç»æ¥è¿‘å°¾å£°äº†ï¼Œå¦‚æœä½ æœŸé—´ä¹Ÿå¾ˆé¡ºåˆ©çš„æˆåŠŸäº†ï¼Œå¯ä»¥ Cheers äº†:)

# å°ç»“
æœ¬ç¯‡æ ¸å¿ƒå‘å¤§å®¶åˆ†äº«äº†å¦‚ä½•ä»¥å¤šç§æ–¹å¼éƒ¨ç½²PyFlinkä½œä¸šã€‚æœŸæœ›åœ¨PyFlink1.10å‘å¸ƒä¹‹åï¼Œå¤§å®¶èƒ½æœ‰ä¸€ä¸ªé¡ºåˆ©å¿«é€Ÿä½“éªŒçš„å¿«æ„Ÿï¼åœ¨å¼€ç¯‡è¯´é“éƒ¨åˆ†ï¼Œä¸ºå¤§å®¶åˆ†äº«äº†è€å­å€¡å¯¼å¤§å®¶çš„ â€œè‡´è™šæï¼Œå®ˆé™ç¬ƒã€‚ä¸‡ç‰©å¹¶ä½œï¼Œå¾ä»¥è§‚å…¶å¤â€çš„å¤§é“ï¼ŒåŒæ—¶ä¹Ÿç»™å¤§å®¶å¸¦æ¥äº†2020çš„ç¥ç¦ï¼Œç¥ç¦å¤§å®¶ "2020 å®‰ï¼"ã€‚











